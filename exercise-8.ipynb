{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 8: Tracking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some code cells will be marked with \n",
    "```\n",
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "```\n",
    "\n",
    "This indicates that you are being asked to write a piece of code to complete the notebook."
   ],
   "metadata": {
    "id": "JWC5tKyP3x1e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following two pip installation commands may raise some warnings regarding a `deepcell 0.10.0` dependency conflict. You can ignore the warning and proceed with the rest of the notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/vanvalenlab/deepcell-tf.git@update-tracking-app-models --no-dependencies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install deepcell-tracking spektral tensorflow-addons pydot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download data\n",
    "!wget https://storage.googleapis.com/datasets-spring2021/nuclear.gif"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "from IPython.display import HTML\n",
    "from deepcell.utils.plot_utils import get_js_video"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem framing\n",
    "\n",
    "Given robust segmentation models, cell tracking can be framed simply as a problem of connecting objects between frames. To begin examining this problem, we will start by loading a time lapse movie of fluorescent nuclei."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nuclear_file = 'nuclear.gif'\n",
    "im = imageio.get_reader(nuclear_file)\n",
    "images = []\n",
    "for frame in im:\n",
    "    images.append(frame)\n",
    "images = np.stack(images, axis=0)\n",
    "x = np.expand_dims(images[:, 250:, 250:], axis=-1)\n",
    "print(x.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "HTML(get_js_video(np.expand_dims(x, axis=0),\n",
    "                  batch=0, cmap='gray'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize nuclear model\n",
    "\n",
    "The application will download pretrained weights for nuclear segmentation. For more information about application objects, please see our [documentation](https://deepcell.readthedocs.io/en/master/API/deepcell.applications.html)."
   ],
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from deepcell.applications import NuclearSegmentation\n",
    "\n",
    "app = NuclearSegmentation()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the application to generate labeled images\n",
    "\n",
    "Typically, neural networks perform best on test data that is similar to the training data. In the realm of biological imaging, the most common difference between datasets is the resolution of the data measured in microns per pixel. The training resolution of the model can be identified using `app.model_mpp`."
   ],
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Training Resolution:', app.model_mpp, 'microns per pixel')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resolution of the input data can be specified in `app.predict` using the `image_mpp` option. The `Application` will rescale the input data to match the training resolution and then rescale to the original size before returning the labeled image."
   ],
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = app.predict(x, image_mpp=0.65)\n",
    "\n",
    "print(y_pred.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "HTML(get_js_video(np.expand_dims(y_pred, axis=0),\n",
    "                  batch=0, cmap='viridis'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can see that the nuclear model successfully created a label mask for each cell however if you look closely you can see that the label of each cells changes over time. After tracking the cells, we want the label to be consistent over time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear assignment approach to cell tracking\n",
    "\n",
    "Now that we have a set of nuclear objects labeled in each frame, cell tracking can be framed simply as a problem of connecting objects in frame $n$ to objects in frame $n+1$. However we need to also deal with the possibility that cells can die or divide into new daughter cells. In order to accomodate this complication, we have adapted a linear assignment framework first introduced by Jaqaman et al (2008). The goal of the linear assignment algorithm is to select a set of pairs such that the sum of the selected weights is minimized. In the framework established by Jaqaman et al, the cost matrix is divided into four quadrants. The top left and bottom right corners correspond to direct matches between objects in frame n to objects in frame $n+1$. The bottom left corner is populated by a diagonal matrix where diagonal values correspond to the probability of a cell dividing. The top right corner is filled with another diagonal matrix in which the diagonal values correspond to the probability of cell death. A diagram of the cost matrix is shown below. \n",
    "\n",
    "\n",
    "[Jaqaman et al (2008). Robust single-particle tracking in live-cell time-lapse sequences. Nature methods, 5(8), 695-702.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2747604/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Linear Assignment Process](./LAP_Process.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate IoU\n",
    "In order to populate the top left and bottom right corners of the cost matrix, we can begin by using the intersection-over-union of each pair of objects between frame $n$ and frame $n+1$. This metric gives us a measurement of the overlap between objects. First, write a function to calculate the intersection-over-union between two cells."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "def calculate_iou(mask1, mask2):\n",
    "    \"\"\"Calculates intersection-over-union between two binary masks\n",
    "    \n",
    "    Args:\n",
    "        mask1 (np.array): Binary array for the mask of one cell\n",
    "        mask2 (np.array): Binary array for the mask of the second cell\n",
    "        \n",
    "    Returns:\n",
    "        float: IoU value\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare IoU Matrix\n",
    "We can now use the function `calculate_iou` as the basis for a function that takes in two frames and calculates the iou value for each possible pair of cells between the two frames."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "def prepare_iou_matrix(frame1, frame2):\n",
    "    \"\"\"Prepares a matrix comparing cells in frame 1 to cells in frame2\n",
    "    based on the iou of the two cells\n",
    "    \n",
    "    Args:\n",
    "        frame1 (np.array): Labeled array for the first frame with n cells\n",
    "        frame2 (np.array): Labeled array for the second frame with m cells\n",
    "        \n",
    "    Returns:\n",
    "        np.array: nxm array\n",
    "    \"\"\"\n",
    "    # Relabel both arrays sequentially to make calculations easier\n",
    "    frame1= relabel_sequential(frame1)[0]\n",
    "    frame2 = relabel_sequential(frame2)[0]\n",
    "    \n",
    "    # Add your code here\n",
    "    # Remember to skip the background (0) when calculating iou\n",
    "    \n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect IoU matrix\n",
    "Let's take a look at the iou matrices for 3 frames, two of which have divisions. In the second and third examples you should see that we cannot directly use this matrix to assign cells in the first frame to the second frame because the parent cell in the first frame significantly overlaps with two daughter cells in the second frame."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in [0, 33, 58]:\n",
    "    iou = prepare_iou_matrix(y_pred[i], y_pred[i+1])\n",
    "    fig,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "    ax[0].imshow(y_pred[i,...,0])\n",
    "    ax[0].set_title('Frame {}'.format(i))\n",
    "    ax[1].imshow(y_pred[i+1,...,0])\n",
    "    ax[1].set_title('Frame {}'.format(i+1))\n",
    "    cax = ax[2].imshow(iou)\n",
    "    fig.colorbar(cax, ax=ax[2], shrink=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup cost matrix\n",
    "We are now ready to populate the complete cost matrix beginning first with the IoU matrix that we prepared. The linear assignment algorithm is going to minimize the sum of the scores so we will first initialize the cost matrix with an array of ones. The top left and bottom right corners are set to $1 - \\texttt{IoU}$. The top right corner is an array of ones with the diagonal set to $1 - P(\\texttt{death})$. Finally the bottom left corner is an array of ones with the diagonal set to $1 - P(\\texttt{birth})$. We will start with $P(\\texttt{death})$ and $P(\\texttt{birth})$ equal to 0.5, but these hyperparameters can be tuned to optimize performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_cost_matrix(frame1, frame2, birth_prob, death_prob):\n",
    "    iou = prepare_iou_matrix(frame1, frame2)\n",
    "    \n",
    "    num1 = iou.shape[0]\n",
    "    num2 = iou.shape[1]\n",
    "    nobj = num1 + num2\n",
    "    \n",
    "    matrix = np.ones((nobj, nobj))\n",
    "    \n",
    "    # 1 - iou to top left and bottom right corners\n",
    "    cost = 1 - iou\n",
    "    matrix[:num1, :num2] = cost\n",
    "    matrix[nobj - num2:, nobj - num1:] = cost.T\n",
    "    \n",
    "    # Create diagonal corners with the birth and death rate on diagonals\n",
    "    birth = (birth_prob * np.eye(num2) + np.ones((num2, num2)) - np.eye(num2))\n",
    "    death = (death_prob * np.eye(num1) + np.ones((num1, num1)) - np.eye(num1))\n",
    "    \n",
    "    # Add diagonal cost columns to bottom left and top right corners\n",
    "    matrix[nobj - num2:, :num2] = birth\n",
    "    matrix[:num1, nobj - num1:] = death\n",
    "    \n",
    "    return matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll take a look at the cost matrix for frame 33/34 where there is a division."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = 33\n",
    "cost_matrix = make_cost_matrix(y_pred[t], y_pred[t+1], 0.5, 0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "ax[0].imshow(y_pred[t,...,0])\n",
    "ax[0].set_title('Frame {}'.format(t))\n",
    "ax[1].imshow(y_pred[t+1,...,0])\n",
    "ax[1].set_title('Frame {}'.format(t+1))\n",
    "cax = ax[2].imshow(cost_matrix)\n",
    "fig.colorbar(cax, ax=ax[2], shrink=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform linear assignment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.optimize import linear_sum_assignment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "row_ind, col_ind = linear_sum_assignment(cost_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's map these results into an array so that we can visualize the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mapping = np.zeros((np.max(row_ind)+1, np.max(col_ind)+1))\n",
    "for r, c in zip(row_ind, col_ind):\n",
    "    mapping[r, c] = 1\n",
    "\n",
    "i = 33\n",
    "fig,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "ax[0].imshow(y_pred[i,...,0])\n",
    "ax[0].set_title('Frame {}'.format(i))\n",
    "ax[1].imshow(y_pred[i+1,...,0])\n",
    "ax[1].set_title('Frame {}'.format(i+1))\n",
    "ax[2].imshow(mapping)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "row_ind, col_ind"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep learning for cell tracking\n",
    "\n",
    "While the IoU value for each pair of cells is a useful initial probability of two cells being the same between frames, it is ultimately an imperfect metric. Instead we can train a deep learning model to predict the probability of two cells being the same. The model can use information about the cell and its neighborhood in order to produce an accurate prediction. In the `deepcell_tracking` package, we have introduced the `CellTracker` which handles creating the cost matrix, performing linear assignment, and managing the cell lineage data structure to keep track of the trajectory of cells beween frames. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initalize CellTracking application\n",
    "\n",
    "Create an instance of `deepcell.applications.CellTracking`. You can learn more about how to train this model in [Training and Tracking with GNNs](https://github.com/vanvalenlab/deepcell-tf/blob/master/notebooks/training/tracking/Training%20and%20Tracking%20with%20GNNs.ipynb)"
   ],
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from deepcell.applications import CellTracking\n",
    "\n",
    "tracker = CellTracking()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Track the cells"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tracked_data = tracker.track(np.copy(x), y_pred)\n",
    "y = tracked_data['y_tracked']  # tracked y data"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize tracking results"
   ],
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "HTML(get_js_video(np.expand_dims(y, axis=0),\n",
    "                  batch=0, cmap='viridis'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've finished using `CellTracker.track_cells`, not only do the annotations preserve label across frames, but the lineage information has been saved in `CellTracker.tracks`."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d6958a1e2d76c81394f5edb36466ab16da5019223958cf6d35c8c6937ef865c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('mbl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}